# Cat Dog Classification with Transfer Learning

This project, hosted by [Kaggle](https://www.kaggle.com/tongpython/cat-and-dog), involved building a model to classify images of cats and dogs with the proper labels. I used this as an opportunity to demonstrate how transfer learning can be an effective method to retrain a neural network for a specific purpose. Transfer learning involves taking a fully trained neural network, changing one or more layers of the neural network, and retraining this model with the weights for unaltered layers locked in place.

## Advantages of Transfer Learning
A model that uses transfer learning will not only perform better than one trained from scratch, but it will also train faster. Popular models like ResNet or VGG have been extensively researched with the number of layers and hyperparameters finely curated. These models achieve high accuracy on a wide variety of image classes, and transfer learning utilizes the image's convolutional features that would be resolved by a fully trained ResNet or VGG model. In the transfer learning process, only the output layer of these fully-trained models is modified. Specifically, the dog/cat example replaces the final layer of a ResNet model to output class probabilities for 2 different classes instead of 1000. Since the convolutional layers of the model have their weights held in place, the model only needs to edit weights for the newly created layer. This allows for less variability in how the gradients will act on the models weights, and inevitably produce a more robust model in a smaller amount of time.

The model trained in this repository trains to almost 98% testing accuracy in under training 10 epochs! Not only does transfer learning reduce the time taken to create a trained model, but it also performed considerably better than a model built from scratch. In short, transfer learning can be used as a way of not "reinventing the wheel". Any fully trained network like VGG or ResNet has been trained with a considerable amount of time and an enormous amount of resources; utilizing the information contained in these models' weights can considerably reduce overhead in training a new model.